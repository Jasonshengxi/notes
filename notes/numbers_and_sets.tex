\documentclass[12pt]{article}
\input{../common.tex}

\begin{document}
% Lectured by Dr Zoe Wyatt (zw253)

\section{Introduction}

Expect:
\begin{compactitem}
    \item precise definitions
    \item rigorous proofs
    \item foundational questions
\end{compactitem}

We start with assumptions called \emph{axioms}.

A \emph{statement} is a sentence that can have a true or false value.
A \emph{proof} is a sequence of true statements without logical gaps
establishing some conclusion.

\begin{compactitem}
\item show they are true
\item gain insight into why they are true
\item the proof might be cool
\end{compactitem}

\subsection{Number Systems}

Define $\mathbb{N}$ as the set of natural numbers, $\{1,2,3,\cdots\}$ (note the lack of $0$).
Define $\mathbb{Z},\mathbb{Q},\mathbb{R}$ to be 
integer, rational, and real sets respectively.

A real number is \emph{algebraic} if it is the
root of some polynomial with integer coefficients.
Non-algebraic numbers are called \emph{transcendental}.

The existence of a transcendental number was shown in 1844.

\subsection{Some Proofs and Nonproofs}

\begin{claim}
    For all positive integers $n$, $n^{3} - n$ is always a multiple of $3$.
\end{claim}
\begin{proof}
    Let $n \in \mathbb{N}$, we have $n^{3} - n = n(n^{2} - 1) = (n - 1) \times n \times (n+1)$.
    One of the three consecutive integers $n-1,n,n+1$ must be a multiple of $3$.
    Thus, the product $n^{3} - n$ must also be a multiple of $3$.
\end{proof}

Note the little box given for free by \LaTeX, on the right side of the page.
That denotes the end of the proof.

\begin{claim}
    For any positive integer $n$, if $n^{2}$ is even then so is $n$.
\end{claim}
\begin{nonproof}
    Given $n \in \mathbb{N}$, we can write $n = 2k$ where $k \in \mathbb{N}$.
    We have $n^{2} = 4k^{2} = 2(2k^{2})$, which is even.
\end{nonproof}

\begin{proof}
    Suppose on the contrary that $n^{2}$ is even so $n = 2k+1$ for some $k \in \mathbb{N}$.
    Then we have,
    \[
    \begin{aligned}
        n^{2} = (2k+1)^{2} &= 4k^{2} + 4k + 1 \\
                     &= 4(k^{2} + k) + 1.
    \end{aligned}
    \]
    which is odd, contradicting the assumption that $n^{2}$ is even.
    \contra
\end{proof}

\begin{claim}
    The \sol{} to $x^{2} - 5x + 6 = 0$ is $x = 2$ or $x = 3$.
\end{claim}
\begin{proof}
    If $x = 2$ or $x = 3$,
    then $x - 2 = 0$ or $x - 3 = 0$.
    So $(x-2)(x-3) = x^{2} - 5x + 6 = 0$.

    If $x^{2}-5x+6=0$, then
    $(x-2)(x-3)=0$,
    so either $x-2=0$ or $x-3=0$,
    which yields $x=2$ or $x=3$.
\end{proof}

Alternatively, we can write
\begin{proof}
    \begin{align*}
        &x=2 \quad \text{or} \quad x=3\\
        \iff &x-2=0 \quad\text{or}\quad x-3=0 \\
        \iff &(x-2)(x-3)=0\\
        \iff &x^{2}-5x+6=0
    \end{align*}
\end{proof}

\begin{claim}
    Every positive real number is greater than or equal to $1$.
\end{claim}
\begin{nonproof}
    Let $r$ be the least positive real.
    Either $r = 1$ or $r < 1$ or $r > 1$.

    If $r < 1$, then $0 < r^{2} < r$, 
    so $r^{2}$ is a smaller positive real. \contra

    If $r > 1$, then $0 < \sqrt{r} < r$,
    so $\sqrt{r}$ is a small positive real. \contra
    
    Thus, $r = 1$.
\end{nonproof}

The problem lies in the nonexistence of a least positive real.
The moral is that
\begin{center}
    \underline{Every claim must be justified}.
\end{center}

\subsection{Combining Claims}

The truth of assertions like $A \land B$ and $A \lor B$ depend on
the truth of $A$ and $B$, as summarised in the \emph{truth table}:

\begin{table}[h]
    \centering
    \begin{tabular}{ |c|c|c|c|c|c|c| }
        \hline
        A & B & $A \land B$ & $A \lor B$ & $\neg A$ & $A \Rightarrow B$ \\
        \hline
        F & F & F & F & T & T\\
        F & T & F & T & T & T\\
        T & F & F & T & F & F\\
        T & T & T & T & F & T\\
        \hline
    \end{tabular}
    \caption{The truth table of various logical constructs.}
\end{table}

Note, for example, that $\neg (A \land B)$ is equivalent to
$(\neg A) \lor (\neg B)$, by comparing truth tables.
Similarly, $A \Rightarrow B$ is equivalent to $(\neg A) \lor B$,
and hence $B \lor (\neg A)$,
and hence to $(\neg B) \Rightarrow (\neg A)$.
This is called the \emph{contrapositive}.

\subsubsection*{Negating Quantifiers}

A claim may involve "quantifiers" like $\forall$ or $\exists$.
$\neg(\forall x, A(x))$ is equivalent to $\exists x, \neg A(x)$.
Similarly, $\neg(\exists x, A(x)) \iff \forall x, \neg A(x)$.

\section{Sets, Functions, and Relations}

\subsection{Sets}

A \emph{set} is a collection of mathematical objects.
For example, $\mathbb{R}$, $\mathbb{N}$, $\{1,5,9\}$, $(-2,3]$.

Two important facts required for a set are that 
\begin{compactenum}
\item the order of elements in the set is immaterial, and
\item each element in the set occurs only once.
\end{compactenum}

For instance, $\{1,3,7\} = \{1,7,3\}$, and $\{3,4,4,8\} = \{3,4,8\}$.

\begin{definition}
    Two sets are equal if they have the same elements. 
    That is, $A = B$ iff $\forall x, x \in A \iff x \in B$.
\end{definition}
There is only one \emph{empty set} $\emptyset$ i.e. the set with no elements.

\begin{definition}
    A set $B$ is a \emph{subset} of $A$, written $B \subseteq A$, or $B \subset A$,
    if every element of $B$ is an element of $A$, or equivalently $\forall x \in B, x \in A$.
    $B$ is said to be a \emph{proper subset of A} if $B \subseteq A$ and $B \ne A$,
    sometimes written $B \subsetneq A$.
\end{definition}

Note that $A = B$ iff $A \subseteq B$ and $B \subseteq A$.


For example, $\{u \in \mathbb{N} : n\text{ is prime}\} = \{2,3,5,7,11,\cdots\}$.

\begin{definition}
    For $A,B$ sets, their \emph{union} $A \cup B$ is
    given by $\{x : x \in A \lor x \in B\}$.
    Their \emph{intersection} $A \cap B$ is defined to be
    $\{x : x \in A \land x \in B\}$.
    We say $A$ and $B$ are \emph{disjoint} if $A \cap B = \emptyset$.
\end{definition}

Note that we can view intersection as a special case of subset selection,
in that $A \cap B = \{x \in A : x \in B\}$.

\begin{definition}
    For $A,B$ sets, their \emph{set difference} $A \setminus B$ is defined by $\{x \in A : x \notin B\}$.
\end{definition}
Note that set difference is non-commutative, whereas $\cap$ and $\cup$ 
are commutative and associative.
Interestingly, $\cup$ and $\cap$ are distributive over each other, in that
\begin{align*}
    A \cup (B \cap C) = (A \cup B) \cap (A \cup C),\\
    A \cap (B \cup C) = (A \cap B) \cup (A \cap C).
\end{align*}
Also,
\begin{align*}
    A \setminus (B \cap C) = (A \setminus B) \cup (A \setminus C),\\
    A \setminus (B \cup C) = (A \setminus B) \cup (A \setminus C).
\end{align*}

Let's prove one of them.
\begin{theorem}
    If $A,B,C$ are sets, we have $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$.
\end{theorem}
\begin{proof}
    Let $x \in A \cap (B \cup C)$.
    Then we have $x \in A$ and $x \in B \cup C$,
    which means that $x \in A$ and also either $x \in B$ or $x \in C$.
    If $x \in B$, since $x \in A$, we have $x \in A \cap B$.
    Similarly, if $x \in C$, we have $x \in A \cap C$.
    Thus, $x \in A \cap B$ or $x \in A \cap C$, so $x \in (A \cap B) \cup (A \cap C)$.
    Thus, we have $A \cap (B \cup C) \subseteq (A \cap B) \cup (A \cap C)$.

    Conversely, if $x \in (A \cap B) \cup (A \cap C)$,
    then either $x \in A \cap B$ or $x \in A \cap C$.
    If $x \in A \cap B$, then we have both $x \in A$ and $x \in B$,
    so $x \in B \cup C$, and therefore $x \in A \cap (B \cup C)$.
    Similarly, if $x \in A \cap C$, then
    $x \in B \cup C$ anyway, and $x \in A \cap (B \cup C)$.
    Thus, we have $(A \cap B) \cup (A \cap C) \subseteq A \cap (B \cup C)$.

    Finally, $(A \cap B) \cup (A \cap C) = A \cap (B \cup C)$.
\end{proof}

\begin{definition}
    If $A_{1},A_{2},A_{3},\cdots$ are sets, then
    \begin{align*}
        \bigcap_{n=1}^{\infty} A_n &= A_{1} \cap A_{2} \cap A_{3} \cap \cdots\\
                                   &= \{x : x \in A_n \ \forall n \in \mathbb{N}\}
    \end{align*}
    and similarly,
    \begin{align*}
        \bigcup_{n=1}^{\infty} A_n &= A_{1} \cup A_{2} \cup A_{3} \cup \cdots\\
                                  &= \{x : x \in A_n \text{ for some } n \in \mathbb{N}\}
    \end{align*}
\end{definition}
Note that these definitions do not utilize any limits.
This definition can be trivially applied to
a collection of sets $A_i$ indexed by $i \in I$,
this time denoted $\bigcap\limits_{i \in I} A_i$.

\begin{definition}
    Given sets $A$ and $B$, we can form their \emph{cartesian product} by
    \[
        A \times B = \{(a,b) : a \in A, b \in B\}.
    \]
    which is the set of \emph{ordered} pairs $(a,b)$ with $a \in A$ and $b \in B$.
\end{definition}

Note that $(a,b)$ can be defined by $\{\{a,b\},a\}$. 
Similarly, we can have cartesian product of more, using ordered $n$-ples.

\begin{definition}
    The \emph{power set} of a set $X$, denoted $\mathcal{P}(X)$,
    is the set of all subsets of $X$,
    \[
    \mathcal{P}(X) = \{Y : Y \subseteq X\}
    \]
\end{definition}
For example, if $X=\{a,b\}$, we have $\mathcal{P}(X) = \{\emptyset,\{a\},\{b\},X\}$.

All subset selections must be confined, in that
$\{x : P(x)\}$ must be specified by $\{x \in A : P(x)\}$.
In fact, suppose we have $X=\{x : x\text{ is a set}, x \notin x\}$.
We ask if $X \in X$. If so, then $X \notin X$ is false,
so $X \notin X$. But if not, then $X \notin X$ is true,
so $X \in X$. Thus, two contradictions appear.
This is known as \emph{Russell's Paradox}.

Another deduction we can make from the paradox is that
there is no \emph{universal set}, a set $Y$ that contains
all mathematical objects, i.e. $\forall x, x \in Y$.
If such a set exists, then a contradiction occurs
via Russell's Paradox.

Thus, to guarantee that a set exists,
it should be obtained via known sets.

\begin{definition}
    Write $\mathbb{N}_{0} = \mathbb{N} \cup \{0\} = \{0,1,2,3,\cdots\}$.
    Given $n \in \mathbb{N}_{0}$, we can say a set $A$
    has \emph{size} $n$ if we can write $A = \{a_{1},a_{2},\cdots,a_n\}$,
    with the elements $a_i$ distinct.
\end{definition}

\begin{definition}
    We say $A$ is \emph{finite} if there exists $n \in \mathbb{N}_{0}$
    such that $A$ has size $n$.
    Otherwise, we say that $A$ is \emph{infinite}.
\end{definition}

\subsection{Functions}

Informally, given sets $A,B$, a function $f$ from $A$ to $B$,
is a "rule" that assigns to every $x \in A$ a unique $f(x) \in B$.
More formally,

\begin{definition}
    A \emph{function} from $A$ to $B$, denoted $f: A \to B$ is a subset $f \subseteq A \times B$
    such that for all $x \in A$, 
    there is a unique $y \in B$ such that $(x, y) \in f$.
    If $(x,y) \in f$, we write $f(x) = y$, or $x \mapsto y$.
\end{definition}

Exmaples:
\begin{compactenum}[(1)]
\item $f: \mathbb{R} \to \mathbb{R}$, where $x \mapsto x^{2}$, is a function.
\item $f: \mathbb{R} \to \mathbb{R}$, where $x \mapsto x^{-1}$, is not a function, 
    since it is not defined at $0$.
\item $f: \mathbb{R} \to \mathbb{R}$, where $x \mapsto \pm\sqrt{|x|}$, is not a function,
    since it is multi-valued.
\item $f: \mathbb{R} \to \mathbb{R}$ yielding $1$ if $x \in \mathbb{Q}$ and $0$ otherwise,
    is a function.
\end{compactenum}

\begin{definition}
    Given $f: A \to B$, we say $A$ is the \emph{domain of $f$}
    and $B$ is the \emph{range of $f$}, or codomain of $f$.
\end{definition}

\begin{definition}
    Given $f: A \to B$ and $x,y \in A$ such that $f(x) = y$,
    we say $y$ is the \emph{image} of $x$,
    and $x$ is a \emph{preimage} of $y$.
\end{definition}

Note that images are unique but preimages are not. 
For example, if $f(x) = x^{2}$, then
the image of $6$ is $36$, but $36$ has two preimages, $6$ and $-6$.

\begin{definition}
    Given $f: A \to B$ and $X \subseteq A$,
    the \emph{image of $X$ under $f$} is
    \[
        f(X) = \{f(x) : x \in X\} = \{b \in B : f(x) = b \text{ for some } x \in X\}.
    \]
\end{definition}

Here is where some more stuff about functions
should've been defined, like surjection, injection,
and bijection, if I didn't wake up 40 minutes late.

Define the indicator function $\indic A$:
\[
i_A(x) = \begin{cases}
    1 & x \in A\\
    0 & \text{otherwise}\\
\end{cases}
\]
It has the following properties:
\begin{compactenum}[(i)]
\item $\indic A = \indic B \iff A = B$.
\item $\indic{A\cap B} = \indic A \indic B$.
\item $\indic{X\setminus A} = 1 - \indic A$.
\item $\indic {A\cup B} = \indic A + \indic B - \indic {A \cap B}$.
\end{compactenum}

Given $f: A \to B$ and $g : B \to C$,
the composition is $g \circ f: A \to C$, defined by
$a \mapsto g(f(a))$.
In general, it is not commutative,
but it is associative.
Using this definition, $f: A\to B$ is \emph{invertible}
if there exists $g : B \to A$ such that $g \circ f = \id A$ and $f \circ g = \id A$.

Note that the condition on both sides is important,
take for example $f : \mathbb{N} \to \mathbb{N}$ defined by $x \mapsto x+1$
and $g : \mathbb{N} \to \mathbb{N}$ defined by $x \mapsto x-1$ if $x > 1$, and otherwise $1 \mapsto 1$.
We have $g \circ f = \id{\mathbb{N}}$ but $f \circ g \ne \id{\mathbb{N}}$
since $f \circ g(1) = f(1) = 2 \ne 1$.

\begin{lemma}
    A function $f : A \to B$ is left invertible
    iff it is injective.
\end{lemma}

\begin{proof}
    Given that $f : A \to B$ is left invertible,
    there exists $g : B \to A$ such that $g \circ f = \id A$.
    In this case, consider $a_{1},a_{2} \in A$ such that $f(a_{1}) = f(a_{2})$.
    Taking $g$ on both sides, we have $g(f(a_{1})) = g(f(a_{2}))$,
    but by definition we have $a_{1} = a_{2}$.
    Thus, a left invertible map is always injective.
    In particular, an invertible map is injective.

    Converly, let $f : A \to B$ an injective map.
    We can find $g : B \to A$ such that $g \circ f = \id A$.
    We consider the image of $A$ under $f$, $f(A)$.
    Any $b \in f(A)$ is trivially invertible
    by taking $g(b)$ to be the unique element $a \in A$
    that has $f(A) = b$, whose existence is guaranteed by $b \in f(A)$.
    For any $c \in B \setminus f(A)$, we can select any value to be $g(c)$,
    since $g(f(a))$ will never output the value $g(c)$.
\end{proof}

\begin{lemma}
    A function $f$ is right invertible iff 
    it is surjective.
\end{lemma}

\begin{proof}
    Given $f: A \to B$ is right invertible,
    there exists $g : B \to A$ such that $f \circ g = \id A$.
    we need $f(g(B)) = B$, so $f$ must be surjective.

    Conversley, if $f$ is surjective, we can find $g : B \to A$
    with $f \circ g = \id B$ by taking $g(b) = a$
    for each $b$ by taking any $a \in A$ such that $f(a) = b$,
    whose existence is guaranteed by surjectivity.
\end{proof}

\begin{corollary}
    A function $f$ is invertible if and only if it is bijective.
\end{corollary}

We write $f^{-1} : B \to A$ for the inverse of $f$ if it exists.

\subsection{Relations}
\begin{definition}
    A relation on a set $X$ is a subset $R \subseteq X \times X$.
    We write $aRb$ if $(a,b) \in R$.
\end{definition}

\begin{definition}
    A relation is \emph{reflexive} if $xRx$ holds true for all $x \in X$.
\end{definition}
\begin{definition}
    A relation is \emph{symmetric} if $xRy \implies yRx$ holds true for all $x,y \in X$.
\end{definition}
\begin{definition}
    A relation is \emph{transitive} if $xRy \land yRz \implies xRz$ for all $x,y,z \in X$.
\end{definition}

\begin{definition}
    A relation $R$ is an equivalence relation if it is
    reflexive, symmetric, and transitive.
    Equivalence relations are often denoted $a \sim b$.
\end{definition}

If $\sim$ is an equivalence relation on $X$, then 
the \emph{equivalence class} of $x \in X$ is
defined by $[x] = \{y \in X : y \sim x\}$.

Given a set $X$, a \emph{partition} of $X$ is
a collection of pairwise disjoint subsets
whose union is $X$.

\begin{theorem}
    Let $\sim$ be an equivalence relation on $X$.
    Then the equivalence classes of $\sim$ form a partition of $X$.
\end{theorem}
\begin{proof}
    Since $\sim$ is reflexive, we have $x \in [x]$ for all $x \in X$.
    Thus,
    \[
        \bigcup_{x \in X}[x] = X
    \]
    It remains to prove that either $[x] \cap [y] = \emptyset$ or $[x] = [y]$,
    for any $x,y \in X$.

    Suppose $[x] \cap [y] \ne \emptyset$, then pick $z \in [x] \cap [y]$.
    Then we have $z \sim x$ and $z \sim y$, so by symmetry and transitivity
    we have $x \sim z \sim y$, so $x \sim y$.

    Then, for any $a \in [x]$, we have $a \sim x \sim y$, so $a \sim y$,
    thus $a \in [y]$, and $[x] \subseteq [y]$. By symmetry,
    we also have $[y] \subseteq [x]$ so $[x] = [y]$.

    Thus, if $[x] \cap [y] \ne \emptyset$, then $[x] = [y]$.
\end{proof}

Conversely, given a partition of $X$,
there is an equivalence relation $R$ whose
equivalence classes are precisely 
the parts of the partition.

It can be trivially constructed by defining $aRb$ if
$a,b$ lie in the same part. Alternatively, let $A_i$
be the parts of the partition, then
\[
R = \{(a,b) \in X \times X : \exists i\ a \in A_i \land b \in A_i\}
\]

Given an equivalence relation $R$ on a set $X$,
the \emph{quotient of $X$ by $R$}, denoted $X/R$, is 
the set of equivalence classes:
\[
    X/R = \{[x] : x \in X\}
\]
The map $q : X \to X/R$ defined by $q(x) = [x]$ is
the \emph{quotient map} or the projection map.

On $\mathbb{Z} \times \mathbb{N}$ define $(a,b)\mathbb{R}(c,d)$ if
$ad = bc$. Note that if you consider $(a,b)$ as a notation of $a/b$, then
\[
\frac{a}{b} = \frac{c}{d} \iff ad = bc
\]
so $(\mathbb{Z} \times \mathbb{N})/R$ is equivalent to $\mathbb{Q}$.

\subsection{Binary Operations}

\begin{definition}
    A \emph{binary operation} $*$ on a set A is a function $A \times A \to A$.
\end{definition}

\begin{definition}
    We say $*$ is \emph{commutative} if $x * y = y * x$.
\end{definition}

\begin{definition}
    We say $*$ is \emph{associative} if $(x * y) * z = x * (y * z)$.
\end{definition}

\begin{definition}
    Let $\odot$ binary operation on $A$, we say that
    $*$ is distributive over $\odot$ if
    \begin{align*}
        x * (y \odot z) &= (x * y) \odot (x * z)\\
        (y \odot z) * x &= (y * x) \odot (z * x)
    \end{align*}
\end{definition}

\section{Integers and Counting}

The natural numbers $\mathbb{N}$ is a set containing
a special element ``1'', together with a map
$S: \mathbb{N} \to \mathbb{N}$ that maps $n$ to its successor such that
\begin{compactenum}[(i)]
\item $S(n) \ne 1$ for all $n \in \mathbb{N}$.
\item $S$ is injective, i.e. $S(m) = S(n) \implies m = n$ for all $m,n \in \mathbb{N}$.
\item Let $A$ be a subset of $\mathbb{N}$ st $1 \in A$ and 
    $n \in A \implies S(n) \in A$ for all $n \in \mathbb{N}$,
    then $A = \mathbb{N}$.
\end{compactenum}
These are called the \emph{Peano Axioms}.
We call axiom (iii) the axiom of induction.
We can now define $2$ to be $S(1)$, $3$ to be $S(2)$, etc.
We can also define addition by defining
\begin{compactitem}
\item $n+1 = S(n)$,
\item $n + S(m) = S(n + m)$.
\end{compactitem}
Similarly for multiplication, we have
\begin{compactitem}
\item $n \times 1 = n$,
\item $n \times S(m) = n \times m + n$.
\end{compactitem}

We can show by induction that these definitions
satisfy the usual rules of arithmetic.

We can also define an ordering $m < n$ if $m + k = n$
for some $k \in \mathbb{N}$. It is transitive.
A key feature of $<$ is that for $m \ne n$,
exactly one of $m < n$ or $n < m$ holds.
This makes it a total order.

The axiom of induction (axiom (iii))
is also known as the \emph{weak principle of induction} (WPI).
It states that \\
``if $P(1)$ holds, and $\forall n \in \mathbb{N} \quad P(n) \implies P(n+1)$,
then $P(n)$ holds for all $n \in \mathbb{N}$''

A different form of induction based on the ordering
is the \emph{strong principle of induction} (SPI). It states that\\
``if $P(1)$ holds and ($\forall n \in \mathbb{N}$, if
$P(m)$ holds for all $m < n$, then $P(n+1)$ holds),
then $P(n)$ holds for all $n \in \mathbb{N}$.''

The two principles are equivalent.
SPI implies WPI trivially,
and SPI implies WPI by taking $P(n)$ to be
``$Q(m)$ holds for all $m < n$''.

The above ordering of $\mathbb{N}$ satisifes
a special property called the \emph{well-ordering principle} (WOP):
every nonempty subset of $\mathbb{N}$ has a minimal element.\\
i.e. if $P(n)$ holds for $n \in A \subset \mathbb{N}$ with $A \ne \emptyset$,
then there exists a least $m \in A$ s.t. $P(m)$ holds.

\begin{theorem}
    SPI $\implies$ WOP
\end{theorem}
\begin{proof}
    Suppose, for contradiction, that
    there is no least $n \in \mathbb{N}$ s.t. $P(n)$ holds.
    Consider $Q(n) = \neg P(n).$
    Certainly $P(1)$ is false, else $1$ would be the minimal element.
    Thus $Q(1)$ holds true.
    
    Given $n \in \mathbb{N}$, suppose that $Q(k)$ is true
    for all $k < n$.
    Then, $P(k)$ is false for all $k < n$.
    So $P(n)$ is false as otherwise $n$ would
    be the minimal element.
    Thus, $Q(n)$ holds.

    We invoke SPI, yielding that $Q(n) = \neg P(n)$
    holds for all $n \in \mathbb{N}$.
    This contradicts with the assumption that
    $P(n)$ holds for some $n \in A$.
\end{proof}

Interestingly, $WOP \centernot\implies SPI$.

\begin{theorem}[Half of the Fundamental Theorem of Arithmetic]
    Any natural number $n > 1$ can be written as a product of primes.
\end{theorem}
\begin{proof}
    Let $C$ be the set of natural numbers
    greater than one that cannot be written as a product of primes.

    We assume $C \ne \emptyset$ and derive a contradiction.
    By the WOP, $C$ has a least element, say $m$.
    Clearly $m$ cannot be prime, since then it would
    be the product of itself,
    so $m = ab$ with $1 < a,b < m$. At least
    one of $a$ or $b$ cannot have a prime factorization,
    since if both did then $m$ would have one.
    However $a < m$ must then have $a \in C$,
    so $m$ is not the minimum element. 
    Thus, a contradiction arises.
\end{proof}

\subsection{Finite Sets}
Recall a set $A$ has size $n$ if
we can write $A = \{a_{1},a_{2},\cdots,a_n\}$ 
with the elements $a_i$ pairwise distinct.
We write $|A| = n$ or $\#A = n$.
We say $A$ is finite if there exists $n \in \mathbb{N}_0$
such that $|A| = n$, and $A$ is infinite otherwise.

\begin{prop}
    A set of size $n$ has exactly $2^{n}$ subsets.
\end{prop}
\begin{proof}
    We will prove by induction on $n$.
    Clearly empty sets have one subset, the empty set,
    so it is true for $n=0$.

    Given $n > 0$ and $T \subseteq \{1,2,\cdots,n-1\}$,
    how many $S \subseteq \{1,2,\cdots,n\}$ are there
    s.t. $S \cap \{1,2,\cdots,n-1\} = T$?
    There are exactly two, namely $T$ and $T \cup \{n\}$.
    Hence the number of subsets of $\{1,2,\cdots,n\}$
    is equal to twice the number of different $T$,
    which is $2 \times 2^{n-1} = 2^{n}$.
\end{proof}

This proposition can also be written $|\mathcal{P}(A)| = 2^{|A|}$.

Given $n \in \mathbb{N}_0$ and $0 \le k \le n$, we write $\binom nk$
for the number of subsets of an $n$-element set
that are of size $k$. $\binom nk$ is
called a \emph{binomial coefficient}. In other words,
\[
\binom nk = \biggl|\{S \subseteq \{1,2,\cdots,n\}: |S| = k\}\biggr|
\]
From this, we can see that $\sum_{k=0}^{n}\binom nk = |\mathcal{P}(\{1,2,\cdots,n\})| = 2^{n}$.

Recall that
\[
    \binom nk = \binom{n-1}{k-1}+\binom{n-1}k
\]
Indeed the nunber of subsets
of $\{1,2,\cdots,n\}$ of size $k$ that does not include
$n$ is $\binom{n-1}k$, while the number of subsets of $\{1,2,\cdots,n\}$ of
size $k$ that do not include $n$ is $\binom{n-1}{k-1}$.

The \emph{Pascal's Triangle} is obtained from this.
I'm not writing the rest of it down.

\begin{prop}
    \begin{align*}
        \binom nk 
        &= \frac{n(n-1)(n-1)\dots(n-k+1)}{k(k-1)(k-2)\cdots(2)(1)}\\
        &= \frac{n!}{k!(n-k)!}
    \end{align*}
\end{prop}
\begin{proof}
    Given a set of size $n$, there
    are $n$ ways to pick the first element,
    $n-1$ ways to pick the second element,
    and so on. Thus,
    there are $n(n-1)(n-1)\dots(n-k+1)$ ways of picking $k$ elements,
    in order, one-by-one.

    However, every subset of size $k$ is
    picked $k!$ times due to different permutations,
    so the number of subsets is exactly the ratio in the proposition.
\end{proof}

Note that the formula tells as that
\begin{align*}
    \binom n 2 &= \frac{n(n-1)}{2} \approx \frac{n^{2}}{2}\\
    \binom n 3 &= \frac{n(n-1)(n-2)}{6} \approx \frac{n^{3}}{6}
\end{align*}
for really large $n$.

\begin{theorem}[Binomial Theorem]
    For all $a,b \in \mathbb{R}, n \in \mathbb{N}$,
    we have
    \begin{align*}
        (a+b)^{n} &= \binom n 0 a^{n} + \binom n 1 a^{n-1}b + \cdots 
               + \binom n{n-1}ab^{n-1} + \binom nn b^{n}\\
               &= \sum_{r=0}^{n}\binom nr a^{n-r}b^{r}
    \end{align*}
\end{theorem}
\begin{proof}
    When we expand $(a+b)^{n} = (a+b)(a+b)\cdots(a+b)$,
    we obtain terms of the form $a^{n-k}b^{k}$ where $0 \le k \le n$,
    and the number of terms of this form is exactly $\binom nk$
    since we are selecting from $n$ factors of the form $a+b$
    $k$ terms of the form $b$.
\end{proof}

For example,
\[
    (1+x)^{n} = \sum_{r=0}^{n}\binom nr x^{r}
\]
which is useful since $x^{r}$ vanishes with large $r$
when $x \ll 1$.

What can we say about the relationship
between sizes of unions and intersections
of finite sets?

For example,
\[
    \abs{A \cup B} = \abs{A} + \abs{B} - \abs{A \cap B}.
\]
Intuitively, $\abs{A} + \abs{B}$ certainly counts
all the elements in $A \cup B$, but it double counts
elements in both, so we subtract $\abs{A \cap B}$ to compensate.

Also,
\[
\abs{A \cup B \cup C} = \abs{A} + \abs{B} + \abs{C}
- \abs{A \cap B} - \abs{A \cap C} - \abs{B \cap C} + \abs{A \cap B \cap C}.
\]
It can be obtained through very similar reasoning.

\begin{theorem}[Inclusion Exclusion Principle]
    Let $S_{1},S_{2},\cdots,S_n$ be finite sets. Then
    \[
        \abs{S_{1}\cup S_{2}\cup \cdots \cup S_n} =
        \sum_{\abs{A}=1}\abs{S_A} - \sum_{\abs{A}=2}\abs{S_A}
        +\sum_{\abs{A}=3}\abs{S_A} - \cdots + (-1)^{n+1}\sum_{\abs{A}=n}\abs{S_A}
    \]
    where $S_A = \bigcap_{i \in A} S_i$ and $\sum\limits_{\abs{A}=k}$
    sums over all sets $A \subseteq \{1,\cdots,n\}$ of size $k$.
\end{theorem}

Equivalently,
\[
    \abs{\bigcup_{i=1}^{n} S_i} 
    = \sum_{r=1}^{n}(-1)^{r+1} \sum_{
        \substack{A\subseteq\{1,\cdots,n\}\\\abs{A}=r}
    } \abs{\bigcap_{i\in A} S_i}.
\]
\begin{proof}
    Let $x \in S_{1}\cup S_{2}\cup\cdots S_n$,
    say $x \in S_i$ for $k$ of the $S_i$.
    We want $x$ to be counted exactly once in the RHS.
    We have
    \begin{align*}
        \abs{\{A : \abs{A}=1 \text{ with } x \in S_A\}} &= k\\
        \abs{\{A : \abs{A}=2 \text{ with } x \in S_A\}} &= \binom k 2,
    \end{align*}
    and in general,
    \[
        \abs{\{A : \abs{A}=r \text{ with } x \in S_A\}} = \binom k r.
    \]
    Note that if $r > k$, then the expression is $0$.
    Thus the number of times that $x$ is counted
    on the RHS is exactly
    \begin{align*}
        &k - \binom k 2 + \binom k 3 - \cdots + (-1)^{k+1} \binom k k\\
        &= 1 - \biggl(
            1 - k + \binom k 2 - \binom k 3 + \cdots + (-1)^{k} \binom k k
        \biggr)\\
        &= 1 - (1 + (-1))^{k} = 1 - 0 = 1
    \end{align*}
    Thus $x$ is counted exactly once.
\end{proof}

\section{Elementary Number Theory}

\subsection{Primes}

Given $a,b \in \mathbb{Z}$, we say ``$a$ divides $b$'' if
there exists $c \in \mathbb{Z}$ such that $b = ac$.
We might also say ``$a$ is a divisor of $b$''
or ``$a$ is a factor of $b$'' or ``$b$ is a multiple of $a$''.
We also write $a \mid b$.

From this, we can notice that $\pm 1$ and $\pm b$
always divide $b$. We call all other
factors \emph{proper} (or non-trivial).

\begin{definition}
    A natural number $n \ge 2$
    is \emph{prime} if its only factors
    are trivial factors.
    Otherwise, it is composite.
\end{definition}

Note that only numbers $n \ge 2$ can be prime or composite.
For example, $1$ is neither.

\section{Real Numbers}
\section{(Un)Countability}

\appendix

\newpage
\section{Notation}

We write $A \implies B$ for "if A then B".
We write \sol{} for a solution, as in the \sol{} of a polynomial, or $3$ is a \sol{}.

If $A$ and $B$ are assertions,
we can (but usually don't) write $A \land B$ for "A and B",
and $A \lor B$ for "A or B".
We can similarly write $\neg A$ for "not A".

We write $x \in A$ if $x$ is an element of the set $A$, and $x \notin A$ if not.

If $A$ is a set and $P$ is a property of (some) elements of $A$,
we can write $\{x \in A : P(x)\}$ for the subset of $A$ comprising
of the elements $x$ for which $P(x)$ holds true.

We use the notation $\id X : X \to X$ for the identity function on the set $X$,
and $\indic A : X \to \{0,1\}$ for the indicator function of $A \subseteq X$.

\end{document}
