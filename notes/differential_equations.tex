\documentclass[12pt]{article}
\input{../common.tex}

\begin{document}
% Lectured by Christopher Thomas
% Email: c.e.thomas@damtp.cam.ac.uk

\setcounter{section}{-1}
\section{Introduction}

DEs are cool.

For example, Newton's
\[
    m \diff[2]xt = F(x,t)
\]
Where $m$ is mass, $F$ is force, and we call
$x$ the \emph{dependent variable} and $t$ the \emph{independent variable}.

\section{Basic Calculus}

\subsection{Differentiation}

\begin{definition}\label{def:derivative}

    The derivative of a fn $f(x)$ wrt its argument $x$ is
    the function
    \[
        \diff f x = \lim_{h\to 0}\frac{f(x+h) - f(x)}{h}.
    \]
    For the derivative to exist, we require the left-handed
    and right-handed limits to both exist and be equal.
\end{definition}

For example, $|x|$ is not differentiable at $0$ since
the right limit is $1$ and the left limit is $-1$.
(it is however differentiable everywhere else)

\subsubsection*{Order parameters}

Consider the behavior of a function close to a limiting point, $x_{0}$.

\subsubsection*{Big O}

\emph{Big O} roughly means \emph{can be bounded by}.

\begin{definition}
    For finite $x_{0}$, we say
    $f(x)$ is $O(g(x))$ as $x \to x_{0}$ if
    there exists $\delta >0$ and $M > 0$ s.t.
    for all $x$ with $0 < |x - x_{0}| < \delta $,
    we have $|f(x)| \le M|g(x)|$.
\end{definition}

It follows that $\dfrac{f(x)}{g(x)}$ is bounded as $x \to x_{0}$.

Note that this definition is for $x_{0}$ finite,
whereas most usages of $O$, for instance for time complexity,
uses it as $x_{0} = \infty$.

Examples:
\begin{compactitem}
    \item $x \ne O(x^{2})$ as $x \to 0$.
    \item $x^{2} = O(x)$ as $x \to 0$.
    \item $x = O(\sqrt{x})$ as $x \to 0$.
    \item $\sin(2x) = O(x)$ as $x \to 0$, since $|\sin 2x| \le 2|x|$ for all $x$.
\end{compactitem}

\begin{definition}
    For infinite $x_{0}$, we say
    $f(x)$ is $O(g(x))$ as $x \to \infty$
    if there exists $x_{1}$ and $M > 0$ s.t.
    for all $x > x_{1}$, we have
    $|f(x)| \le M|g(x)|$.
\end{definition}

For example, $2x^{3}+4x+12 = O(x^{3})$ as $x \to \infty$.

\subsubsection*{Little o}
\emph{Little o} roughly means \emph{much smaller than}.
It is written $\underline{o}$ in handwritten math, 
to distinguish from $O$.

\begin{definition}
    For finite $x_{0}$, we say
    $f(x)$ is $o(g(x))$ as $x \to x_{0}$ if,
    for any $\varepsilon > 0$, there exists $\delta >0$ s.t.
    for all $0 < |x - x_{0}| < \delta $,
    we have $|f(x)| \le \varepsilon |g(x)|$.
\end{definition}

Note that if $g(x) \ne 0$ in the vicinity of $x_{0}$,
but not necessarily at $x_{0}$, the above definition is equivalent to
\[
\lim\limits_{x\to x_{0}} \frac{f(x)}{g(x)} = 0.
\]
For example, $x^{2} = o(x)$ as $x \to 0$, since $\lim\limits_{x \to 0} \frac{x^{2}}{x} = 0$.

The infinite definition is similar.

\subsubsection*{Notes}

\textbf{$f(x) = o(g(x))$ is a stronger statement than $f(x) = O(g(x))$}.
Intuitively, big $O$ means bounded by some given multiple,
whereas little $o$ means bounded by any multiple.

Thus, $f(x) = o(g(x))$ implies $f(x) = O(g(x))$,
but the converse does not hold.

\textbf{Constants \emph{don't} matter}. 
If $f(x) = O(g(x))$, then $af(x) = O(g(x))$ and $f(x) = O(ag(x))$
for any $a \ne 0$.

\subsubsection*{Usage}

Order parameters are useful to classify remainder terms before taking limits.
Let $\varepsilon (h)$ in
\[
f(x_{0}+h) - f(x_{0}) = hf'(x_0) + \varepsilon (h),
\]
for some finite $h$. Then we have,
by dividing by $h$ on both sides and taking the limit,
\[
\lim\limits_{h \to 0}\left[\frac{f(x_{0}+h)-f(x_{0})}{h}\right]
= f'(x_{0}) + \lim\limits_{h \to 0}\left[\frac{\varepsilon (h)}{h}\right]
\]
The limit on the RHS vanishes by the definition of $f'$.
Therefore, $\varepsilon (h) = o(h)$ as $h \to 0$.

\newpage
\subsection{Rules for Differentiation}

\begin{theorem}[Chain Rule]
    Given $f(x) = F(g(x))$, we have
    \[
    \diff f x = F'(g(x)) \diff gx = \diff Fg \diff gx,
    \]
    where $F'$ denotes the derivative of $F$ wrt to its argument,
    and $F'(g(x))$ denotes the evaluation of that derivative at $g(x)$.
\end{theorem}

\begin{theorem}[Product Rule]
    Given $f(x) = u(x)v(x)$, we have
    \[
    \diff f x = v \diff ux + u \diff vx.
    \]
\end{theorem}

\begin{theorem}[Leibniz's Rule]
    Given $f(x) = u(x)v(x)$, we have
    \[
    f^{(n)} = \sum\limits_{r=0}^{n}\binom nr \left(u^{(r)} \cdot v^{(n-r)}\right).
    \]
\end{theorem}

\subsection{Taylor Series}

For $f(x)$ infinitely differentiable at a point $x = x_{0}$,
the \emph{Taylor series of $f$ about $x_{0}$} is 
\[
T_{f}(x) = \sum\limits_{r=0}^{\infty} \frac{f^{(r)}(x_{0})}{r!}(x - x_{0})^{r}.
\]
We define the \emph{Taylor polynomial of degree n}, $P_{n}(x)$, to be
the truncation of the Taylor series up to the $n$th term, i.e.
\[
P_{n}(x) = \sum\limits_{r=0}^{n} \frac{f^{(r)}(x_{0})}{r!}(x - x_{0})^{r}.
\]
Note that $P_n(x)$ matches the first $n$ derivatives of $f(x)$
at $x_{0}$.

\subsubsection*{How good of an approximation is it?}

As $h \to 0$, we have
\[
    f(x_{0}+h) = f(x_{0}) + hf'(x_{0}) + o(h).
\]
This extends to Taylor's series, in a result called the \emph{Taylor theorem}.

\begin{theorem}[Taylor's Theorem]
    For $f(x)$ $n$-times differentiable at $x_{0}$, we have
    \[
    f(x_{0}+h) = f(x_{0}) + hf'(x_{0}) + \frac{1}{2!}h^{2}f''(x_{0})
    + \cdots + \frac{h^{n}}{n!}f^{(n)}(x_{0}) + E_n,
    \]
    where $E_n$ denotes the error. We have that
    \[
    E_n = o(h^{n})
    \]
    as $h \to 0$.
\end{theorem}

We cna attain a stronger result if $f$ is $(n+1)$-times differentiable
in some interval $(x_{0},x_{0}+h)$ and $f^{(n+1)}$ is continuous in this range, we have
\[
E_n = O(h^{n+1})
\]
as $h \to 0$. so
\[
E_n = f^{(n+1)}(x_{n}) \frac{h^{n+1}}{(n+1)!}
\]
for some $x_{n}$ with $x_{0} \le x_n \le x_{0} + h$. (See Analysis I)

Note that $E_n = O(h^{n+1})$ is a stronger statement than $o(h^{n})$.
For example, $h^{n+\frac{1}{2}}$ is $o(h^{n})$ but \emph{not} $O(h^{n+1})$ as $h \to 0$.

With $x = x_{0} + h$, Taylor's theorem gives
\[
f(x) = P_n(x) + E_n,
\]
so $P_n(x)$ provides a local approximation to $f(x)$ 
in the vicinity of $x_{0}$ with error $o(h^{n})$ or $O(h^{n+1})$.
If $\lim\limits_{n\to\infty}E_{n} = 0$, then the
Taylor series converges to $f(x)$.

For example, take $f(x) = \exp(x)$ about $x_{0} = 0$,
then $f(x)$ is infinitely differentiable and continuous everywhere, so
\[
E_n = \frac{h^{n+1}}{(n+1)!}\exp(x_n),
\]
for some $0 \le x_n \le h$. (note that $h > 0$.)
Consider the fractional error, we have
\[
    \dfrac{E_n}{\exp(h)}= \frac{h^{n+1}}{(n+1)!}\exp(x_n - h).
\]
We have $-h \le x_n - h \le 0$, so $0 < \exp(x_n - h) \le 1$, so
\[
\frac{E_n}{\exp(h)} \le \frac{h^{n+1}}{(n+1)!}
\]
For a given target accuracy at $x=h$, 
this specifies how large $n$ must be.

\subsection{L'h\^{o}pital's Rule}

\begin{theorem}[L'h\^{o}pital's Rule]
    Let $f(x)$ and $g(x)$ be differentiable at $x_{0}$ with
    continuous first derivatives, and
    \begin{align*}
    \lim\limits_{x\to x_{0}}f(x) = f(x_{0}) = 0,\\
    \lim\limits_{x\to x_{0}}g(x) = g(x_{0}) = 0,\\
    \end{align*}
    Then if $g'(x_{0}) \ne 0$, 
    \[
    \lim\limits_{x\to x_{0}} \frac{f(x)}{g(x)} = 
    \lim\limits_{x\to x_{0}} \frac{f'(x)}{g'(x)},
    \]
    Provided the limit on the RHS exists.
\end{theorem}

\begin{proof}
    Using Taylor's theorem, we have
    \[
    f(x) = f(x_{0}) + (x - x_{0})f'(x_{0}) + o(x - x_{0}),
    \]
    as $x \to x_{0}$ and similarly for $g$. Since $f(x_{0}) = g(x_{0}) = 0$, we have
    \begin{align*}
        \lim\limits_{x\to x_{0}}\frac{f(x)}{g(x)} 
        &= \lim\limits_{x \to x_{0}}
        \left[\frac{f'(x_{0}) + o(x-x_{0})/(x - x_{0})}{g'(x_{0}) + o(x-x_{0})/(x - x_{0})}\right]\\
        &= \frac{\lim\limits_{x\to x_{0}} \cdots}{\lim\limits_{x\to x_{0}} \cdots}\\
        &= \frac{f'(x_{0})}{g'(x_{0})}
        = \lim\limits_{x\to x_{0}} \frac{f'(x)}{g(x)},
    \end{align*}
    by the properties of limits and the continuity of first derivatives.
\end{proof}

L'h\^{o}pital's Rule can be generalized,
for instance if $f'(x) = g'(x) = 0$ and 
$f,g$ have continuous second derivatives,
we have
\[
\lim\limits_{x\to x_{0}}\frac{f(x)}{g(x)} = \lim\limits_{x\to x_{0}}\frac{f''(x)}{g''(x)},
\]
and similarly for higher degrees.


\section{Integration}

\subsection{Integrals as Riemann Sums}

\begin{definition}
    The \emph{integral} of a (suitably well defined)
    function $f(x)$ is the limit of a sum. For example,
    \[
        \int_{a}^{b}f(x)dx = \lim_{N\to\infty}\sum_{n=0}^{N-1} f(x_n)\Delta x
    \]
    where $\Delta x = (b-a)/N$, $x_n = a + n\Delta x$.
\end{definition}

\begin{center}
    \begin{tikzpicture}
    \draw[->] (0,0) -- (5, 0) node[right] {$x$};
    \draw[->] (0,0) -- (0, 5) node[above] {$y$};
    \draw[color=red, domain=1:4] plot (\x, \x*\x/4 + 0.5)
        node[above right] {$f(x)$};
    \foreach \x in {1,1.25,...,1.75,3,3.25,...,3.75}
    \draw (\x, 0) rectangle ++(0.25, {\x*\x/4 + 0.5});
    \draw (2.5, 0.75) node {$\cdots$};
\end{tikzpicture}
\end{center}

$f(x)$ is \emph{Riemann integrable} if generalised sum
doesn't dpened on exactly how choose the rectangles in the limit
that all $\Delta x \to 0$, for instance if $\Delta x$ was non-uniform.

Consider one rectangle,
\begin{center}
    \begin{tikzpicture}
    \draw[->] (0,0) -- (5, 0) node[right] {$x$};
    \draw[->] (0,0) -- (0, 5) node[above] {$y$};
    \draw[color=red, domain=1:4] plot (\x, \x*\x/6 + 2)
        node[above right] {$f(x)$};
    \def\x{1.5}
    \draw (\x, 0) node[below] {$x_n$} rectangle ++(2, {\x*\x/6 + 2});
    \draw ({\x + 2}, 0)
        node[below] {$x_{n+1}$};
    \draw[dashed] ({\x + 2}, {\x*\x/6 + 2})
        -- ({\x + 2}, {(\x+2)*(\x+2)/6+2});
\end{tikzpicture}
\end{center}


The Mean value theorem states that
for $f(x)$ continuous, the area under the curve from $x_n$ to $x_{n+1}$ is
\[
A_n = (x_{n+1}-x_n)f(c_n)
\]
for some $x_n \le c_n \le x_{n+1}$.
If $f(x)$ is differentiable,
\begin{align*}
    f(c_n) &= f(x_n) + o(c_n - x_n)\\
           &= f(x_n) + o(\Delta x)
\end{align*}
substituting we get
\[
A_n = \Delta x f(x_n) + o((\Delta x)^{2})
\]
So the total area from $a$ to $b$ is
\begin{align*}
    A &= \lim_{N \to \infty} \sum_{n=0}^{N-1}A_n\\
      &= \lim_{N\to\infty} \sum_{n=0}^{N-1}f(x_n)\Delta x 
      + \lim_{N\to\infty} N O \left[\left(\frac{b-a}{N}\right)^{2}\right]\\
      &= \int_a^b f(x) dx + \lim_{N\to\infty}O(1/N)\\
      &= \int_a^b f(x) dx
\end{align*}
Thus, the integral is the area.

\subsection{Fundamental theorem of Calculus (FTC)}

\begin{theorem}[FTC]
    Let $F(x) = \int_0^x f(t)dt$. then,
    \[
        \diff Fx = \diff{}x \left[\int_a^x f(t)dt\right] = f(x)
    \]
\end{theorem}
\begin{proof}
    \begin{align*}
        \diff Fx &= \lim_{h\to 0}\frac{1}{h}\left[\int_a^{x+h}f(t)dt
        - \int_a^x f(t) dt\right]\\
                 &= \lim_{h\to 0}\frac{1}{h}
                 \int_x^{x+h}f(t)dt\\
                 &= \lim_{h\to 0}\frac{1}{h}\biggl[
                     f(x)h + O(h_{2})\biggr]\\
                 &= \lim_{h\to 0} f(x) + O(h)\\
                 &= f(x)
    \end{align*}
\end{proof}

Note that this $F(x)$ is a solution to $\diff Fx = f(x)$,
specifically the solution with $F(a)=0$.

Some corollaries:
\begin{align*}
    \diff{}x \int_x^b f(t)dt &= -f(x)\\
    \diff{}x \int_x^{g(x)} f(t)dt &= \diff{}x F(g(x)) = \diff Fg \diff gx\\
                                  &= f(g(x)) \diff gx
\end{align*}

\subsection{Integration Techniques}

\subsubsection*{Substitution}

Substitute.

\subsubsection*{Trigonometric Substitutions}

Substitute.

\begin{table}[h]
    \centering
    \begin{tabular}{c|c}
        Integrand & Substitute \\
        \hline
        $\sqrt{1 - x^{2}}$ & $\sin\theta $ \\
        $\sqrt{x^{2} + 1}$ & $\sinh\theta $ \\
        $\sqrt{x^{2} - 1}$ & $\cosh\theta $ \\
        $1 + x^{2}$ & $\tan\theta $ \\
        $1 - x^{2}$ & $\tanh\theta $ \\
    \end{tabular}
\end{table}

\subsubsection*{Integration by parts}

Recalling the product rule, we have $(uv)'=u'v + uv'$, 
rearranging and adding integral signs yields
\[
\int uv'dx = uv - \int u'v dx.
\]
\section{Partial Differentiation}
\subsection{Functions of Several Variables}

Differentiating \emph{multivariate functions}.

% Contour plot:
% \begin{center}
%     \begin{tikzpicture}
%         \draw[->] (-3, -3) -- (3, -3) node [right] {$x$};
%         \draw[->] (-3, -3) -- (-3, 3) node [right] {$y$};
%         \foreach \x in {0.5, 1.0, 1.4, 1.7}
%         \draw (0, 0) ellipse ({1.5*\x cm} and \x cm);
%     \end{tikzpicture}
% \end{center}

\subsection{Partial Derivatives}

\begin{definition}
    Given a function of several variables, say $f(x,y)$,
    the \emph{partial derivative} of $f$ wrt $x$ at fixed $y$ is
    \[
        \left.\diffp{f}{x}\right|_{y} 
            = \lim_{\delta x \to 0} \frac{f(x+\delta x,y) - f(x,y)}{\delta x}.
    \]
\end{definition}
Note that this can be interpreted as
the slope of $f$ when moving in the $+x$ direction.

We also shorten many things, like
\[
    f_x \equiv \diffp f x
\]
or
\[
    f_{xy} \equiv \diffp f{yx}
\]
Note that if $f$ has continuous second derivatives then
\[
    \diffp f{xy} = \diffp f{yx}
\]
This is known as Schwarz's theorem.

\subsection{Multivariate Chain Rule}

Given path $x(t),y(t)$ and $f(x,y)$,
what is $\diff ft$ along the path?

Consider a small change in $f$, under $(x,y) \mapsto (x + \delta x, y+\delta y)$.
\begin{align*}
    \delta f &= f(x + \delta x, y + \delta y) - f(x,y)\\
             &= f(x + \delta x, y + \delta y) - f(x + \delta x,y)\\
             &+ f(x + \delta x, y)  - f(x,y)
\end{align*}
By Taylor's theorem, $f(x+\delta x,y) - f(x,y) = f_x(x,y)\delta x + o(\delta x)$.\\
For the other half, we have, 
\begin{align*}
    f(x+\delta x,y + \delta y) - f(x,y + \delta y) 
    &= f_y(x + \delta x,y)\delta y + o(\delta y)\\
    &= \biggl(f_y(x,y) + f_{yx}(x, y)\delta x + o(\delta x)\biggr)\delta y + o(\delta y)
\end{align*}
Substituting, we have
\[
    \delta f = \biggl(f_y(x,y) + f_{yx}(x,y)\delta x + o(\delta x)\biggr)\delta y
    + f_x(x,y)\delta x + o(\delta y) + o(\delta x)
\]
Taking the limit when $\delta x \to 0$ and $\delta y \to 0$, we have
\[
    \mathrm{d} f = \diffp f x \mathrm{d} x + \diffp f y \mathrm{d} y
\]
For the final answer, we have
\begin{align*}
    \diff{}t f(x(t),y(t)) 
    &= \lim_{\delta x,\delta y,\delta t\to 0} 
    \left(\diffp f x \frac{\delta x}{\delta t} + \diffp f y \frac{\delta y}{\delta t}\right)\\
    &= \diffp f x \diff x t + \diffp f y \diff y t
\end{align*}
If we ask for $\diff f x$ instead, we have
\begin{align*}
    \diff fx &= \diffp f x \diff x x + \diff fy \diff yx\\
             &= \diffp fx + \diff fy \diff yx
\end{align*}

\subsubsection*{Integral form of chain rule}

For the change in $f$ between two end points, denoted $\Delta f$, we have
\[
    \Delta f = \int \di f = \int \diffp fx \di x + \int \diffp fy \di y
\]
which is trivial from substituting $\diff ft$.

\subsection{Applications of the Multivariate Chain Rule}

\subsubsection*{Change of Coordinates}

Is it often useful to rewrite differential equations
in a different coordinate system.
For example converting cartesian $(x,y)$ to 
polar $(r,\theta )$ in order to exploit circular symmetry.

To rewrite a function $f(x,y)$ into $(r,\theta)$,
consider functions $x(r,\theta)$ and $y(r,\theta)$
which specify the method of coordinate change.
substitute those to produce $f(x(r,\theta),y(r,\theta ))$.
differentiate this using the multivariate chain rule,
we have
\[
    \left.\diffp{f}{r}\right|_{\theta } = \left.\diffp{f}{x}\right|_{y}\left.\diffp{x}{r}\right|_{\theta }
                + \left.\diffp{f}{y}\right|_{x}\left.\diffp{y}{r}\right|_{\theta }
\]
Similarly,
\[
    \left.\diffp{f}{\theta }\right|_{r} = \left.\diffp{f}{x}\right|_{y}\left.\diffp{x}{\theta }\right|_{r}
                + \left.\diffp{f}{y}\right|_{x}\left.\diffp{y}{\theta }\right|_{r}
\]

\subsubsection*{Implicit Differentiation}

For $f(x,y,z)$,
\[
\di f = \left.\diffp{f}{x}\right|_{y,z} \di x + \left.\diffp{f}{y}\right|_{x,z} \di y + \left.\diffp{f}{z}\right|_{x,y} \di z
\]
Consider the equation $f(x,y,z) = \text{const}$,
which defines a surface in 3D space.
This implicitly defines functions
$z = z(x,y)$, $x = x(y,z)$, $y = y(x,z)$,
which are solutions of the surface.
It may be considerably difficult to find those functions however.
Implicit differentiation can be used to find the
derivatives of those functions with comparably
little effort.

For example, take $f(x,y,z) = xy + y^{2}z+ z^{5}$, and $f(x,y,z) = 1$.
\[
    \left.\diffp{f}{x}\right|_{y} = y + y^{2}\left.\diffp{z}{x}\right|_{y} + 5z^{4}\left.\diffp{z}{x}\right|_{y} = 0
\]
Notice that in this case, $z$ is not held constant in the partial derivative.
Rearranging yields
\[
\left.\diffp{z}{x}\right|_{y} = -\frac{y}{y^{2} + 5z^{4}}
\]
In general, for $f(x,y,z) = \text{const}$, we have
\[
    0 = \di f = \left.\diffp{f}{x}\right|_{y,z}\di x + \left.\diffp{f}{y}\right|_{x,z}\di y + \left.\diffp{f}{z}\right|_{x,y}\di z
\]
which shows a dependence between $\di x, \di y, \di z$.
Thus, in general, we can differentiate wrt $x$ holding $y$ constant to get
\[
0 = \left.\diffp{f}{x}\right|_{y} = \left.\diffp{f}{x}\right|_{y,z}\left.\diffp{x}{x}\right|_{y}
            + \left.\diffp{f}{y}\right|_{x,z}\left.\diffp{y}{x}\right|_{y}
                    +\left.\diffp{f}{z}\right|_{x,y}\left.\diffp{z}{x}\right|_{y}
\]
Simplifying terms, we have
\[
0 = \left.\diffp{f}{x}\right|_{y} = \left.\diffp{f}{x}\right|_{y,z}
                    +\left.\diffp{f}{z}\right|_{x,y}\left.\diffp{z}{x}\right|_{y}
\]
Thus,
\[
    \diffpc{z}{x}{y} = -\frac{\diffpc{f}{x}{y,z}}{\diffpc{f}{z}{x,y}}
\]
Notice that using this equation for $\diffpc{x}{y}{z}$ and $\diffpc{y}{z}{x}$
yields
\[
\diffpc{x}{y}{z}\diffpc{y}{z}{x}\diffpc{z}{x}{y} = -1
\]

\subsubsection*{Reciprocal Rule}

Consider the reciprocal rule:
\[
\diff yx = \left(\diff xy\right)^{-1}
\]
In partial derivatives, it applies if the same variables are held fixed.
\[
\diffpc{x}{z}{y} = -\frac{\diffpc{f}{z}{x,y}}{\diffpc{f}{x}{y,z}}.
\]
Similarly,
\[
\diffpc{z}{x}{y} = -\frac{\diffpc{f}{x}{y,z}}{\diffpc{f}{z}{x,y}}.
\]
Thus,
\[
\diffpc{z}{x}{y} = \frac{1}{\diffpc{x}{z}{y}}.
\]

\subsection{Differentiating integrals wrt a parameter}

Consider a family of functions $f(x;c)$. Define
\[
    I(c) = \int_{a(c)}^{b(c)} f(x;c) \di x
\]
and now we wish to compute $\diff Ic$.
We claim
\begin{theorem}
    \[
    \diff Ic = 
    \int_{a(c)}^{b(c)}\diffp fc (x;c) \di x
    + f(b(c);c)\diff bc
    - f(a(c);c)\diff ac
    \]
\end{theorem}
\begin{proof}
    \begin{align*}
        \diff Ic 
        &= \lim_{\delta c \to 0}\frac{1}{\delta c}
        \left[
            \int_{a(c+\delta c}^{b(c+\delta c)} f(x;c+\delta c) \di x
        - \int_{a(c)}^{b(c)} f(x;c) \di x
        \right]\\
        &= \lim_{\delta c \to 0}\frac{1}{\delta c}
        \left[
            \int_{a(c)}^{b(c)} f(x;c+\delta c) \di x
            +\int_{b(c)}^{b(c+\delta c)} \cdots \di x
            -\int_{a(c)}^{a(c+\delta c)} \cdots \di x
            - \int_{a(c)}^{b(c)} f(x;c) \di x
        \right]\\
        &= \lim_{\delta c \to 0}\frac{1}{\delta c}
        \left[
            \int_{a(c)}^{b(c)} f(x;c+\delta c)
            - f(x;c) \di x
            +\int_{b(c)}^{b(c+\delta c)} \cdots \di x
            -\int_{a(c)}^{a(c+\delta c)} \cdots \di x
        \right]\\
        &= 
            \int_{a(c)}^{b(c)} \diffp fc (x;c) \di x
        + \lim_{\delta c \to 0}\frac{1}{\delta c}
        \left[
            \int_{b(c)}^{b(c+\delta c)} f(x;c+\delta c) \di x
            -\int_{a(c)}^{a(c+\delta c)} f(x;c+\delta c) \di x
        \right]\\
        &= 
        \cdots
        + \lim_{\delta c \to 0}\frac{1}{\delta c}
        \left[
            \biggl(b(c+\delta c) - b(c)\biggr)f(\bar x ; c + \delta c)
            -\int_{a(c)}^{a(c+\delta c)} f(x;c+\delta c) \di x
        \right]\\
        &= 
        \int_{a(c)}^{b(c)} \diffp fc (x;c) \di x
        + \diff bc f(b(c); c)
        - \lim_{\delta c \to 0}\frac{1}{\delta c}
        \left[
            \int_{a(c)}^{a(c+\delta c)} f(x;c+\delta c) \di x
        \right]\\
        &= 
        \int_{a(c)}^{b(c)} \diffp fc (x;c) \di x
        + \diff bc f(b(c); c)
        - \diff ac f(a(c); c)
    \end{align*}
    where $\bar x$ denotes a value
    obtained from the mean value theorem, with $b(c) \le \bar x \le b(c + \delta c)$.
    another usage of similar variable has been ommitted.
\end{proof}

This theorem can be used as a trick to evaluate certain expressions. Let
\[
I(\lambda ) = \int_{0}^{\lambda }e^{-\lambda x^{2}}\di x,
\]
then we have
\[
\diff I\lambda = \int_{0}^{\lambda }-x^{2}e^{-\lambda x^{2}}\di x + e^{-\lambda ^{3}}
\]
For a more useful expression, consider $J_n = \displaystyle\int_{0}^{\infty}x^{n}e^{-x}\di x$.
Let
\[
I(\lambda ) = \int_{0}^{\infty}e^{-\lambda x}\di x = \frac{1}{\lambda }.
\]
Then we have
\[
    \diff[n]I\lambda = \int_{0}^{\infty} (-x)^{n}e^{-\lambda x}\di x 
    = \frac{(-1)^{n} n!}{\lambda ^{n+1}}
\]
If we set $\lambda =1$, then
\begin{align*}
    (-1)^{n}J_n &= (-1)^{n} n!\\
    J_n &= n!
\end{align*}
which one may notice gives a continuous definition of the factorial.

\section{First Order Linear Differential Equations}

Terminology:
\begin{compactenum}[(i)]
\item An $n$th order differential equation has highest order derivative $n$.
\item A \emph{linear} differential equation has dependent variable appearing linearly.
\item \emph{Ordinary} differential equations only involve functions of one variable.
\end{compactenum}

\subsection{Prelude : Exponential Function}

\begin{definition}
    The exponential function is defined by
    \[
    \exp(x) = \sum_{n=0}^{\infty} \frac{1}{n!}x^{n}
    \]
\end{definition}
Note that it can be equivalently written,
\[
\exp(x) = \lim_{k\to\infty}\left(1+\frac{x}{k}\right)^{k}
\]
by the binomial theorem.

From the definition, it is trivially true that $\diff {}x \exp(x) = \exp(x)$.
In fact, it is equivalent to define $\exp$ by the unique function such that
\[
\diff fx = f
\]
with boundary condition $f(0) = 1$.
Under these definitions, we have $\exp(x_{1})\exp(x_{2}) = \exp(x_{1}+x_{2})$.
With this property, it is more reasonable to write $e^{x} = \exp(x)$.

We define the inverse function $\ln$ by $\exp(\ln x) = x$.
It follows that $a^{x} = (e^{\ln a})^{x} = \exp(x\ln a)$,
which makes it easy to differentiate exponentials.

\begin{definition}
    An \emph{eigenfunction} of the derivative operator
    is a function that is unchanged, up to multiplicative
    scaling by the \emph{eigenvalue}, under the action of operator.
\end{definition}

In other words, If $f$ is an eigenfunction of the derivative operator,
\[
    \diff{}x f(x) = \lambda f(x)
\]
and $\lambda$ is the eigenvalue.

This, we have $\exp(\lambda x)$ as eigenfunctions of the derivative operator.

\subsection{First-order Linear ODEs}

We have that any $n$th order linear ODE has $n$
linearly independent solutions. 
This will not be proven here.

A homogeneous ODE is one in which
all terms involve the dependent variable
or its derivative.
This implies that $y=0$ is a trivial solution.

\subsubsection{Homogeneous Linear ODEs with constant coefficients}

Constant coefficients are coefficients where the independent variables
(often $x$ or $t$) does not appear explicitly.

Solutions of linear homogeneous ODEs with constant coefficients
for any order are of the form $e^{\lambda x}$.

For example, consider
\[
5\diff yx - 3y = 0
\]
This has constant coeffs since $5$ and $3$ do not involve $x$.
We can simply let $y = Ae^{\lambda x}$, with $y=A\lambda e^{\lambda x}$,
\[
5\lambda Ae^{\lambda x} - 3A e^{\lambda x} = 0
\]
Since $e^{\lambda x}$ is non-zero and $A=0$ yields
the trivial solution, we have $5\lambda - 3 = 0$, so $\lambda = 3/5$.
Thus,
\[
y = Ae^{3x/5}
\]
We call this the general solution, 
and we call $5\lambda - 3 = 0$ the \emph{characteristic equation}.

To generate a unique solution we require boundary conditions
or initial conditions.
In general, $n$ of these conditions are needed for $n$th order ODEs.

\subsubsection*{Discrete Equations}

It is sometimes useful to consider functions
evaluated at discrete points.

Consider again $5y' - 3y = 0$, where $y(0) = y_{0}$.
We can approximate the equation by discrete form at $\{x_n\}$
where $x_n = nh$.
\[
    \diffc yx{x_n} \approx \frac{y_{n+1}-y_n}{h}
\]
Where $y_n = f(x_n)$. This is known as the \emph{Forward Euler scheme}.
If we simply substitute this into the equation, we have
\begin{align*}
    5\left(\frac{y_{n+1}-y_n}{h}\right) - 3y_n &= 0\\
    y_{n+1} &= \left(1 + \frac{3}{5} h\right)y_n
\end{align*}
This is a recurrence relation for $y_n$.
In this case, we can notice that every step multiplies
by a constant $1 + 3h/5$, so
\[
y_n = \left(1 + \frac{3}{5}h\right)^{n} y_0
\]
We know that $h = x_n/n$, so
\[
y_n = \left(1 + \frac{3x_n}{5n}\right)^{n} y_0
\]
Now take $x_n = x$ as $n \to \infty$. We have
\begin{align*}
\lim_{n\to\infty} y_n 
&= \lim_{n\to\infty} y_{0}\left(1+ \frac{3x}{5} \frac{1}{n}\right)^{n}\\
&= y_{0}\exp(3x/5)
\end{align*}
Which agrees with our original result.

\subsubsection*{Series Solutions}

We will look for a solution in the form of a power series,
\[
y(x) = \sum_{n=0}^{\infty} a_n x^{n}.
\]
Let's examine $5y' - 3y = 0$ again. We have that
\begin{align*}
    y'(x) &= \sum_{n=0}^{\infty}a_n n x^{n-1} = \sum_{n=1}^{\infty}a_n n x^{n-1}\\
    xy'(x) &= \sum_{n=1}^{\infty} a_n n x^{n}\\
    xy(x) &= \sum_{n=0}^{\infty} a_n x^{n+1} = \sum_{n=1}^{\infty} a_{n-1} x^{n}
\end{align*}
Multiplying our equation by $x$, we have
\begin{align*}
    5xy' - 3xy &= 0\\
    \sum_{n=1}^{\infty}(5na_n - 3a_{n-1})x^{n}&=0\\
    5na_n - 3a_{n-1} &= 0\\
    a_n = \frac{3}{5n}a_{n-1}
\end{align*}
Which is a recurrence relation where $n\ge1$.
In this case, it solves to
\[
a_n = \left(\frac{3}{5}\right)^{n} \frac{a_0}{n!}
\]
Which yields
\begin{align*}
    y(x) 
    &= \sum_{n=0}^{\infty} \frac{a_0}{n!} \left(\frac{3x}{5}\right)^{n}\\
    &= a_0 \exp(3x/5)
\end{align*}
which is indeed the same solution.

\subsubsection{Forced (Non-Homogeneous) ODEs}

Recall that homogeneous means all terms involve 
the dependent variable or its derivative,
a forced ODE has terms with no dependence on 
the dependent variable or its derivatives.
Thus, $y=0$ is no longer a trivial solution.

To solve a forced ODE, do the whole
particular integral complementary function thing.
The method is general for \emph{linear} forced ODEs.

\subsubsection*{Constant Forcing}

A forced ODE is constant forced if it only
has constant terms making it forced.
Those terms are called ``constant forcing terms''.
Take
\[
5y'-3y=10.
\]
Then, $10$ is the constant forcing term.
These equations are easy since $y_p = -10/3$ and $y_c = A\exp(3x/5)$ so
\[
y(x) = Ae^{3x/5} - \frac{10}{3}
\]
Note that the initial conditions must be considered
after the combination.

\subsubsection*{Eigenfunction Forcing}

The forcing term is an eigenfunction of the
derivative operator, i.e. the exponential family.

For example, consider three elements
decaying $A \to B \to C$, with
amounts $a(t),b(t),c(t)$ respectively,
and let their decay rates be $k_a,k_b$.
Then, specifically for $a$, we have
\[
\diff at = -k_a a
\]
so $a(t) = a_0 e^{-k_a t}$. Then
\begin{align*}
    \diff bt 
    &= k_a a - k_b b\\
    &= k_a a_0 e^{-k_a t} - k_b b\\
    \diff bt + k_b b
    &= \mathcolor{blue}{(k_a a_{0}) e^{-k_a t}}
\end{align*}
This ODE is an eigenfunction forced equation,
and the term in blue is the eigenfunction forcing term.
Solve this by guessing the correct function (an exponential).

In this case, we get
\[
b_p(t) = \frac{k_a a_{0}}{k_b - k_a} e^{-k_a t}
\]
Note that $k_a \ne k_b$. Combining with the complementary function, we have
\[
b(t) = De^{-k_b t} + \frac{k_a}{k_b - k_a} a_{0} e^{-k_a t}
\]
To demonstrate an initial condition, let $b(0) = 0$. Then
\[
b(t) = \frac{k_a a_{0}}{k_b - k_a}\left(e^{-k_a t}-e^{-k_b t}\right)
\]
The $k_a = k_b$ case requires a different $b_p$.

\subsubsection{Non-Constant Coefficients}

The general form of the first order linear form may look like 
\[
    a(x) \diff yx + b(x) y = c(x).
\]
The standard form is
\[
\diff yx + p(x) y = f(x).
\]
This is of course solved with the integrating factor.
We simply let $\mu(x)$, then multiply by $\mu$, giving
\[
\mu y' + (\mu p) y = \mu f
\]
So if $\mu' = \mu p$, then $\mu y' + \mu p y = \mu y' + \mu' y = (\mu y)' = \mu f$,
and that becomes solvable. Thus, we solve for
\begin{align*}
    \frac{1}{\mu}\diff \mu x &= p\\
    \ln\mu &= \int p \di x\\
    \mu &= \exp\left(\int p \di x\right)
\end{align*}
Then we have
\[
y = \frac{1}{\mu}\int \mu f \di x.
\]
Armed with this, we can go back to the radioactive decay,
whose core is this equation:
\[
\diff bt + k_b b = k_a a_{0}e^{-k_a t}
\]
The integrating factor is $\mu = e^{k_b t}$, so
\[
    \diff{}t \left(e^{k_b t}b\right) = k_a a_{0} e^{(k_b - k_a)t}
\]
The reveals more clearly the difference when $k_a = k_b$. If so, then
\begin{align*}
    \diff{}t (e^{k_b t}b) &= k_a a_{0}\\
    e^{k_b t}b &= k_a a_{0}t + C\\
\end{align*}
Thus we have
\[
b(t) = k_a a_{0} t e^{-k_b t} + C e^{-k_b t}
\]
The difference being that the particular integral
has an extra $t$.


\appendix

\newpage
\section{Notation}

\subsection{Limits}

For left and right limits, we may write $\lim\limits_{h \to 0^{-}}$ and $\lim\limits_{h \to 0^{+}}.$ 

\subsection{Derivatives}

For derivatives, we may write
\[
    \diff f x = f'(x) = \dot f(x).
\]
Similarly, we have, for a second derivative,
\[
    \diff {}x \diff f x = \diff[2] f x = f''(x) = \ddot f(x).
\]
And for an arbitrary $n$th derivative, we may write
\[
    \diff[n] f x = f^{(n)}(x).
\]

\subsection{Order parameters}

Some may write $f(x) = O(g(x))$ when $f(x)$ is $O(g(x))$.
Some say it is better to write $f(x) \sim O(g(x))$.
It is up to the reader to decide which one is better.

\subsection{Integration}

Indefinite integrals have two notations: $\int f(x)dx$, or $\int^x f(t)dt$.
It has no specified lower limit so the an integration constant appears.

\end{document}
